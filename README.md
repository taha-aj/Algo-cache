# Algo-cache

The goal of this project is to optimize an algorithm by reducing cache misses.

**‚û°Ô∏è French version below**

---

## üá¨üáß English version

### Project: Optimization of the Edit Distance Algorithm

This project explores different strategies for implementing the edit distance algorithm between two sequences, with a focus on optimizing cache memory usage.

### Implemented Methods:

1. **Recursive with memoization**:
   - Classical recursive version with intermediate results stored.
   - Consumes O(N √ó M) memory ‚Äì inefficient for large inputs.

2. **Iterative optimized for memory O(N + M)**:
   - Uses two one-dimensional arrays.
   - Drastically reduces memory usage.
   - Fewer cache misses than the recursive version.

3. **Cache-aware**:
   - Uses blocking with explicit cache size knowledge.
   - Enhances data locality and reuse.
   - More complex but highly efficient.

4. **Cache-oblivious**:
   - Recursive divide-and-conquer strategy without knowing cache size.
   - Enables automatic memory hierarchy optimization.
   - Switches to iterative when subproblems are small.

### Folder Structure:

- `src/`: Contains all source files, including implementations of recursive, iterative, cache-aware, and cache-oblivious versions of the edit distance algorithm.

### Experiments:
- Used `valgrind --tool=cachegrind` to analyze cache misses.
- Measured execution time, CPU time, and energy usage (via RAPL).
- Tested on sequence sizes up to M = 20M and N = 19M.
- Estimated resources needed for real-world genomic sequences.

### Results:
- **Cache-oblivious** is the most efficient method overall.
- Estimated CPU time for test 5: **~35 days**
- Estimated energy usage: **~23.41 kWh**

### Conclusion:
This project demonstrates the major impact of fine-grained cache optimization.  
Despite added complexity, cache-aware and cache-oblivious approaches show substantial performance gains on large-scale problems.

---

## üá´üá∑ Version fran√ßaise

### Projet : Optimisation de l'algorithme de distance d'√©dition

Ce projet explore diff√©rentes strat√©gies d'impl√©mentation de l'algorithme de distance d'√©dition entre deux s√©quences, avec un accent particulier sur l'optimisation de l'utilisation du cache m√©moire.

### M√©thodes abord√©es :

1. **R√©cursif avec m√©mo√Øsation** :
   - Impl√©mentation r√©cursive classique avec stockage des sous-r√©sultats.
   - Consomme O(N √ó M) m√©moire, peu efficace pour de grandes entr√©es.

2. **It√©ratif optimis√© en espace m√©moire O(N + M)** :
   - Utilise deux tableaux unidimensionnels.
   - R√©duction significative de l‚Äôespace m√©moire.
   - Moins de d√©fauts de cache compar√© au r√©cursif.

3. **Cache-aware** :
   - Utilise une strat√©gie de *blocking* avec connaissance de la taille du cache.
   - Meilleure r√©utilisation locale des donn√©es.
   - Impl√©mentation plus complexe, mais tr√®s efficace.

4. **Cache-oblivious** :
   - Version r√©cursive divis√©e en sous-probl√®mes sans connaissance du cache.
   - Acc√®s m√©moire hi√©rarchique optimis√©.
   - Un seuil permet de basculer vers la version it√©rative.

### Structure du d√©p√¥t :

- `src/` : contient tous les fichiers sources, y compris les impl√©mentations r√©cursive, it√©rative, cache-aware et cache-oblivious de l'algorithme de distance d'√©dition.

### Exp√©rimentations :
- Analyse via `valgrind --tool=cachegrind` pour observer les d√©fauts de cache.
- Mesures de temps CPU, temps r√©el et √©nergie (via RAPL).
- Tests sur des tailles allant jusqu‚Äô√† M = 20M et N = 19M.
- Estimation des ressources pour des donn√©es g√©nomiques r√©elles.

### R√©sultats :
- **Cache-oblivious** est la m√©thode la plus performante globalement.
- Temps CPU estim√© pour un grand test : **~35 jours**
- √ânergie consomm√©e estim√©e : **~23,41 kWh**

### Conclusion :
Ce projet montre l‚Äôimpact consid√©rable de la gestion fine du cache.  
Les approches *cache-aware* et *cache-oblivious* apportent des gains notables sur les grandes instances.
